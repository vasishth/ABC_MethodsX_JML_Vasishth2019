---
title: "Using Approximate Bayesian Computation for parameter estimation in the cue-based retrieval model (vague priors)"
author: "Shravan Vasishth"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = TRUE)

libraxry(dplyr)
library(tidyr)
library(ggplot2)

## some helper functions:
rmsd <- function (obs, pred) {
	sqrt(mean((obs - pred)^2, na.rm = TRUE))
}

compute_int_means <- function(d){
	int <- select(filter(d, Distractor=="Match"), -Condition, -Distractor)
	dim(int)
	int$int <- filter(d, Distractor=="Match")$latency - filter(d, Distractor=="Mismatch")$latency
	#
	# means <- group_by(int, Set, Target, lf, ans, mas, mp, rth, bll, lp, ldp, blc, dbl, ndistr) %>% summarise(Effect=mean(int), SE=sd(int)/sqrt(length(int))) %>% ungroup() %>% mutate(lower=Effect-SE, upper=Effect+SE)
	# means
	means <- group_by(int, Set, Target, lf, ans, mas, mp, rth, bll, psc, pic, qcf, qco, cuesim, tprom, dprom, lp, ldp, blc, dbl, ndistr, cueweighting) %>% summarise(Effect=mean(int), SE=sd(int)/sqrt(length(int)), Sji_neg=sum(Sji_neg)) %>% ungroup() %>% mutate(lower=Effect-SE, upper=Effect+SE)
	means
}

convert2log <- function(x){
	ifelse(x>=1, log(x), ifelse(x<=-1, -log(abs(x)), 0))
}

convert2log10 <- function(x){
	x <- ifelse(x>-1 & x<1, 0, x)
	x <- ifelse(x<=-1, -log10(abs(x)), x) 
	x <- ifelse(x>=1, log10(abs(x)), x)
}

```

# Introduction 

## Load interact

The following piece of code, written by Felix Engelmann and available on github, provides the main computation code for ACT-R calculations.

```{r}
source("interACT.R")
```

## Basic engine for generating predictions

Set up priors:

```{r vaguepriors}
a<-2
b<-6
```

```{r}
printcounts<-FALSE

iterate_lf <- function(values,iterations=1000){
  ## values is a scalar or vector containing an lf value or values.
  ## iterations is the number of iterations for that given value.
  ## We need multiple iterations as noise is non-zero and there will be some 
  ## variability due to noise. 
  maxset <- 0
  means <- NULL
  for(v in values){
    lf <<- v
    pmatr <- create_param_matrix(model_4cond, iterations) 
    results <- run(pmatr)
    means2 <- compute_int_means(results)
    means2$Set <- means2$Set+maxset
    means <- bind_rows(means, means2)
  }
  means
}

## set the parameters:
reset_params()
psc <<- 0
qcf <<- 0
cuesim <<- -1
bll <<- 0.5
## default in Engelmann et al 2019 Cog Sci paper
mp <<- 0.15
## default in Engelmann et al 2019 Cog Sci paper
mas <<- 1.5 ## could change this to a random starting value: 
            ## mas <- runif(1,min=1,max=2)
            ## mas<<-sort(rnorm(50,mean=1.5,sd=0.25))
# default in Engelmann et al 2019 Cog Sci paper
ans <<- 0.2
# default in Engelmann et al 2019 Cog Sci paper
rth <<-  -1.5
dbl <<- 0
cueweighting <<- 1 
```

Now generate one run (1000 iterations) with lf as the parameter to be estimated using ABC:

```{r}
## using a large lf value:
means <- iterate_lf(values=0.4)
## grammatical: inhibitory interference effect
means$Effect[1]
## ungrammatical: facilitatory interference effect
means$Effect[2]

# using small lf value:
means <- iterate_lf(values=0.1)
## grammatical: inhibitory interference effect
means$Effect[1]
## ungrammatical: facilitatory interference effect
means$Effect[2]
```

The above runs show the expected pattern: low lf values lead to small effects, and large lf values to large effects.

## Focusing on ungrammatical conditions only

### Model predictions for Dillon et al data

Dillon et al 2013 data (source: Jaeger et al 2019 Bayesian reanalysis):

Grammatical conditions:
 - Agreement  -34, CrI [-85, 15] ms.  Implies Normal(-34,25) if we take a normal approximation
 - Reflexives 2, CrI [-57, 60] ms. Implies Normal(2,30) if we take a normal approximation

Ungrammatical conditions:
 - Agreement -60 ms, CrI [-112, -5] ms.  Implies Normal(-60,33) if we take a normal approximation
 - Reflexives -18 ms, CrI [-72, 36] ms. Implies Normal(-18,27) if we take a normal approximation

In this initial section, we focus only on the ungrammatical conditions when estimating the latency factor parameter.

```{r dillonestimates}
## our data from one subject in one pair of conditions (difference in means):
xbar_au<- -60
## 1 SD above and below mean
lower_au <- -93
upper_au <- -27

xbar_ru<- -18
## 1 SD above and below mean
lower_ru <- -45
upper_ru <- 9
```

#### Estimate lf for ungrammatical agreement and reflexive data:

```{r dillon_au_lf,cache=TRUE}
## Rejection sampling:
nsamp<-5000
lf_posterior<-rep(NA,nsamp)
for(i in 1:nsamp){
  ## generate latency factor value from prior
  latency_factor <<- rbeta(1,a,b) 
## get generated effect for ungrammatical conditions:   
generated_effect<-iterate_lf(latency_factor)$Effect[2]
if(printcounts){
print(paste("count: ",i,sep=" "))
print(paste(lower,generated_effect,upper,sep=" "))
}
  ## if generated effect is within bounds, accept
if((generated_effect>=lower_au & generated_effect<=upper_au) &
   (generated_effect>=lower_ru & generated_effect<=upper_ru)){
  lf_posterior[i]<-latency_factor
} else {
  ## reject
  lf_posterior[i]<- -1
  } 
}

## which samples were rejected?
rejected<-which(lf_posterior==-1)
## acceptance rate:
length(lf_posterior[-rejected])/nsamp

quantile(lf_posterior[-rejected],probs=c(0.025,0.975))
mean(lf_posterior[-rejected])
```

Save the results (if needed):

```{r}
## LF parameter's posterior distribution based on 
## ungrammatical agrmt and refl conditions, based on Dillon data
save(lf_posterior,file="RdaFilesVague/u_lf_D13.Rda")
```

Visualize posterior of lf:

```{r}
hist(lf_posterior[-rejected],main="Ungrammatical conditions \n Dillon et al 2013",
     xlab="Latency factor")
```

#### Estimate predicted range of effects for grammatical and ungrammatical agreement and reflexives using mean lf 

```{r cache=TRUE}
## just computed above:
load("RdaFilesVague/u_lf_D13.Rda")

lf_posterior_accepted<-lf_posterior[-which(lf_posterior==-1)]

n<-length(lf_posterior_accepted)

g_predicted_means<-rep(NA,n)
u_predicted_means<-rep(NA,n)

for(i in 1:n){
  predictions<-iterate_lf(values=lf_posterior_accepted[i])
  ## grammatical:
  g_predicted_means[i]<-predictions$Effect[1]
  ## ungrammatical:
  u_predicted_means[i]<-predictions$Effect[2]
}
```

Save results:

```{r}
save(g_predicted_means,file="RdaFilesVague/g_predicted_means_D13.Rda")
save(u_predicted_means,file="RdaFilesVague/u_predicted_meansD13.Rda")
```

Summary of predicted RTs:

```{r}
summary(g_predicted_means)
summary(u_predicted_means)
```

### Model predictions for JÃ¤ger et al 2019 replication data

Next, we turn to our replication data: 

  - Agreement: -22 [-46, 3]  Implies Normal(-22,13)
  - Reflexives: -23 [-48, 2] Implies Normal(-23,13)
  
```{r dillonerepstimates}
## our data from one subject in one pair of conditions (difference in means):
xbar_aurep<- -22
## 1 SD above and below mean
lower_aurep <- -35
upper_aurep <- -9

xbar_rurep<- -23
## 1 SD above and below mean
lower_rurep <- -36
upper_rurep <- -10
```

#### Estimate lf for ungrammatical agreement data (replication)

```{r dillonrep_u_lf,cache=TRUE}
## Rejection sampling:

nsamp<-5000
lf_posterior<-rep(NA,nsamp)
for(i in 1:nsamp){
  ## generate *random* latency factor value each time
  latency_factor <<- rbeta(1,a,b) 
## get generated effect:   
generated_effect<-iterate_lf(latency_factor)$Effect[2]
if(printcounts){
print(paste("count: ",i,sep=" "))
print(paste(lowerrep,generated_effect,upperrep,sep=" "))
}
  ## if generated effect is within bounds, accept
if((generated_effect>=lower_aurep & generated_effect<=upper_aurep) &
   (generated_effect>=lower_rurep & generated_effect<=upper_rurep)){
  lf_posterior[i]<-latency_factor
} else {
  ## reject
  lf_posterior[i]<- -1
  } 
}

rejected<-which(lf_posterior==-1)
length(lf_posterior[-rejected])/nsamp

quantile(lf_posterior[-rejected],probs=c(0.025,0.975))
mean(lf_posterior[-rejected])
```

```{r}
save(lf_posterior,file="RdaFilesVague/u_lf_D13rep.Rda")
```

Visualize posterior of lf:

```{r}
hist(lf_posterior[-rejected],main="Ungrammatical conditions \n (replication)",xlab="Latency factor")
```

#### Estimate predicted range of effects for ungrammatical agreement data using mean lf  (replication data)


```{r cache=TRUE}
load("RdaFilesVague/u_lf_D13rep.Rda")

lf_posterior_accepted<-lf_posterior[-which(lf_posterior==-1)]

n<-length(lf_posterior_accepted)

g_predicted_means_rep<-u_predicted_means_rep<-rep(NA,n)

for(i in 1:n){
g_predicted_means_rep[i]<-iterate_lf(values=lf_posterior_accepted[i])$Effect[1]
u_predicted_means_rep[i]<-iterate_lf(values=lf_posterior_accepted[i])$Effect[2]
}
```

```{r}
save(g_predicted_means_rep,file="RdaFilesVague/g_predicted_meansD13rep.Rda")
save(u_predicted_means_rep,file="RdaFilesVague/u_predicted_meansD13rep.Rda")
```

Summary of predicted RTs:

```{r}
summary(g_predicted_means_rep)
summary(u_predicted_means_rep)
```

## Focusing on grammatical and ungrammatical conditions

### Model predictions for Dillon et al data

Dillon et al 2013 data (source: Jaeger et al 2019 Bayesian reanalysis):

Grammatical conditions:
 - Agreement  -34, CrI [-85, 15] ms.  Implies Normal(-34,25) if we take a normal approximation
 - Reflexives 2, CrI [-57, 60] ms. Implies Normal(2,30) if we take a normal approximation

Ungrammatical conditions:
 - Agreement -60 ms, CrI [-112, -5] ms.  Implies Normal(-60,33) if we take a normal approximation
 - Reflexives -18 ms, CrI [-72, 36] ms. Implies Normal(-18,27) if we take a normal approximation

```{r dillonestimates2}
## our data from one subject in one pair of conditions (difference in means):

## grammatical:
xbar_ag <- -34
lower_ag <- -34-25
upper_ag <-  -34+25

xbar_rg <- 2
lower_rg <- 2-30
upper_rg <-  2+30

## ungrammatical:
xbar_au<- -60
## 1 SD above and below mean
lower_au <- -93
upper_au <- -27

xbar_ru<- -18
## 1 SD above and below mean
lower_ru <- -45
upper_ru <- 9
```

#### Estimate lf for grammatical and ungrammatical agreement and reflexive data:

Will not work because there is no way the model can predict negative effects for grammatical cases, and that  is what Dillon et al found.

```{r dillon_a_lf,eval=FALSE,cache=TRUE}
## Rejection sampling:
nsamp<-5000
lf_posterior<-rep(NA,nsamp)
for(i in 1:nsamp){
  ## generate latency factor value from prior
  latency_factor <<- rbeta(1,a,b) 
## get generated effect for ungrammatical conditions:   
 generated_effect_g<-iterate_lf(latency_factor)$Effect[1]
 ## get generated effect for ungrammatical conditions:   
 generated_effect_u<-iterate_lf(latency_factor)$Effect[2]

if(printcounts){
print(paste("count: ",i,sep=" "))
print(paste(lower,generated_effect,upper,sep=" "))
}
  ## if generated effect is within bounds, accept
if((generated_effect_u>=lower_au & 
    generated_effect_u<=upper_au) &
   (generated_effect_u>=lower_ru & generated_effect_u<=upper_ru) & 
   (generated_effect_g>=lower_ag & 
    generated_effect_g<=upper_ag) &
   (generated_effect_g>=lower_rg & generated_effect_g<=upper_rg)
   )
  {
  lf_posterior[i]<-latency_factor
} else {
  ## reject
  lf_posterior[i]<- -1
  } 
}

## which samples were rejected?
rejected<-which(lf_posterior==-1)
## acceptance rate:
length(lf_posterior[-rejected])/nsamp

quantile(lf_posterior[-rejected],probs=c(0.025,0.975))
mean(lf_posterior[-rejected])
```

Save the results (if needed):

```{r eval=FALSE}
## LF parameter's posterior distribution based on 
## ungrammatical agrmt and refl conditions, based on Dillon data
save(lf_posterior,file="RdaFilesVague/lf_D13.Rda")
```

Visualize posterior of lf:

```{r eval=FALSE}
hist(lf_posterior[-rejected],main="Dillon et al 2013",
     xlab="Latency factor")
```

#### Estimate predicted range of effects for grammatical and ungrammatical agreement and reflexives using mean lf 

```{r cache=TRUE,eval=FALSE}
## just computed above:
load("RdaFilesVague/u_lf_D13.Rda")

lf_posterior_accepted<-lf_posterior[-which(lf_posterior==-1)]

n<-length(lf_posterior_accepted)

g_predicted_means<-rep(NA,n)
u_predicted_means<-rep(NA,n)

for(i in 1:n){
  predictions<-iterate_lf(values=lf_posterior_accepted[i])
  ## grammatical:
  g_predicted_means[i]<-predictions$Effect[1]
  ## ungrammatical:
  u_predicted_means[i]<-predictions$Effect[2]
}
```

Save results:

```{r eval=FALSE}
save(g_predicted_means,file="RdaFilesVague/g_predicted_means_D13.Rda")
save(u_predicted_means,file="RdaFilesVague/u_predicted_meansD13.Rda")
```

Summary of predicted RTs:

```{r eval=FALSE}
summary(g_predicted_means)
summary(u_predicted_means)
```
